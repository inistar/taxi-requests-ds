{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rtree\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "filename = \"data/2017_Green_Taxi_Trip_Data.csv\"\n",
    "n = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)\n",
    "s = 1000 #desired sample size\n",
    "skip = sorted(random.sample(range(1,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "taxi_df = pd.read_csv(filename, skiprows=skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df['lpep_pickup_datetime'] = pd.to_datetime(taxi_df.lpep_pickup_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df['lpep_dropoff_datetime'] = pd.to_datetime(taxi_df.lpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df['date'] = taxi_df.lpep_pickup_datetime.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df['taxi_duration'] = ((taxi_df.lpep_dropoff_datetime - taxi_df.lpep_pickup_datetime).dt.total_seconds())//60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxi_df = taxi_df.rename(columns={'DOLocationID' : 'taxi_zone'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df['DOW'] = taxi_df.lpep_pickup_datetime.dt.dayofweek.map({0: 'Sunday', 1: \"Monday\", 2: \"Tuesday\", 3: \"Wednesday\", 4:\"Thursday\", 5:\"Friday\", 6:\"Saturday\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df['TOD']= taxi_df.lpep_pickup_datetime.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import date\n",
    "import math\n",
    "\n",
    "def date_extractor(date_str,b,minutes_per_bin):\n",
    "    # Takes a datetime object as a parameter\n",
    "    # and extracts and returns a tuple of the form: (as per the data specification)\n",
    "    # (time_cat, time_num, time_cos, time_sin, day_cat, day_num, day_cos, day_sin, weekend)\n",
    "    # Split date string into list of date, time\n",
    "    \n",
    "    d = date_str.split()\n",
    "    \n",
    "    #safety check\n",
    "    if len(d) != 2:\n",
    "        return tuple([None,])\n",
    "    \n",
    "    # TIME (eg. for 16:56:20 and 15 mins per bin)\n",
    "    #list of hour,min,sec (e.g. [16,56,20])\n",
    "    time_list = [int(t) for t in d[1].split(':')]\n",
    "    \n",
    "    #safety check\n",
    "    if len(time_list) != 3:\n",
    "        return tuple([None,])\n",
    "    \n",
    "    # calculate number of minute into the day (eg. 1016)\n",
    "    num_minutes = time_list[0] * 60 + time_list[1]\n",
    "    \n",
    "    # Time of the start of the bin\n",
    "    time_bin = num_minutes / minutes_per_bin     # eg. 1005\n",
    "    hour_bin = num_minutes / 60                  # eg. 16\n",
    "    min_bin = (time_bin * minutes_per_bin) % 60  # eg. 45\n",
    "    \n",
    "    #get time_cat\n",
    "    hour_str = str(hour_bin) if hour_bin / 10 > 0 else \"0\" + str(hour_bin)  # eg. \"16\"\n",
    "    min_str = str(min_bin) if min_bin / 10 > 0 else \"0\" + str(min_bin)      # eg. \"45\"\n",
    "    time_cat = hour_str + \":\" + min_str                                     # eg. \"16:45\"\n",
    "    \n",
    "    # Get a floating point representation of the center of the time bin\n",
    "    time_num = (hour_bin*60 + min_bin + minutes_per_bin / 2.0)/(60*24)      # eg. 0.7065972222222222\n",
    "    \n",
    "    time_cos = math.cos(time_num * 2 * math.pi)\n",
    "    time_sin = math.sin(time_num * 2 * math.pi)\n",
    "    \n",
    "    # DATE\n",
    "    # Parse year, month, day\n",
    "    date_list = d[0].split('-')\n",
    "    d_obj = date(int(date_list[0]),int(date_list[1]),int(date_list[2]))\n",
    "    day_to_str = {0: \"Monday\",\n",
    "                  1: \"Tuesday\",\n",
    "                  2: \"Wednesday\",\n",
    "                  3: \"Thursday\",\n",
    "                  4: \"Friday\",\n",
    "                  5: \"Saturday\",\n",
    "                  6: \"Sunday\"}\n",
    "    day_of_week = d_obj.weekday()\n",
    "    day_cat = day_to_str[day_of_week]\n",
    "    day_num = (day_of_week + time_num)/7.0\n",
    "    day_cos = math.cos(day_num * 2 * math.pi)\n",
    "    day_sin = math.sin(day_num * 2 * math.pi)\n",
    "    \n",
    "    year = d_obj.year\n",
    "    month = d_obj.month\n",
    "    day = d_obj.day\n",
    "    \n",
    "    weekend = 0\n",
    "    #check if it is the weekend\n",
    "    if day_of_week in [5,6]:\n",
    "        weekend = 1\n",
    "       \n",
    "    return (year, month, day, time_cat, time_num, time_cos, time_sin, day_cat, day_num, day_cos, day_sin, weekend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaner(zipped_row):\n",
    "    # takes a tuple (row,g,b,minutes_per_bin) as a parameter and returns a tuple of the form:\n",
    "    # (time_cat, time_num, time_cos, time_sin, day_cat, day_num, day_cos, day_sin, weekend,geohash)\n",
    "    row = zipped_row[0]\n",
    "    g = zipped_row[1]\n",
    "    b = zipped_row[2]\n",
    "    minutes_per_bin = zipped_row[3]\n",
    "    # The indices of pickup datetime, longitude, and latitude respectively\n",
    "    indices = (1, 6, 5)\n",
    "    \n",
    "    #safety check: make sure row has enough features\n",
    "    if len(row) < 7:\n",
    "        return None\n",
    "    \n",
    "    #extract day of the week and hour\n",
    "    date_str = row[indices[0]]\n",
    "    clean_date = date_extractor(date_str,b,minutes_per_bin)\n",
    "    #get geo hash\n",
    "\n",
    "    latitude = float(row[indices[1]])\n",
    "    longitude = float(row[indices[2]])\n",
    "    location = None\n",
    "    #safety check: make sure latitude and longitude are valid\n",
    "    if latitude < 41.1 and latitude > 40.5 and longitude < -73.6 and longitude > -74.1:\n",
    "        location = geohash.encode(latitude,longitude, g)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return tuple(list(clean_date)+[location])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gclean_rdd = taxi_df.map(lambda row: (row, g, b, minutes_per_bin)).map(data_cleaner).filter(lambda row: row != None).map(lambda row: (row,1)).reduceByKey(lambda a,b: a + b).map(lambda row: (row,'g'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
